{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('titanic.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['PassengerId', 'Survived', 'Pclass', 'Name', 'Sex', 'Age', 'SibSp',\n",
       "       'Parch', 'Ticket', 'Fare', 'Cabin', 'Embarked'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Titanic dataset has been loaded. It contains columns such as `PassengerId`, `Survived`, `Pclass`, `Name`, `Sex`, `Age`, `SibSp`, `Parch`, `Ticket`, `Fare`, `Cabin`, and `Embarked`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Handling Missing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassengerId      0\n",
       "Survived         0\n",
       "Pclass           0\n",
       "Name             0\n",
       "Sex              0\n",
       "Age            177\n",
       "SibSp            0\n",
       "Parch            0\n",
       "Ticket           0\n",
       "Fare             0\n",
       "Cabin          687\n",
       "Embarked         2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check null values\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassengerId    0.000000\n",
       "Survived       0.000000\n",
       "Pclass         0.000000\n",
       "Name           0.000000\n",
       "Sex            0.000000\n",
       "Age            0.198653\n",
       "SibSp          0.000000\n",
       "Parch          0.000000\n",
       "Ticket         0.000000\n",
       "Fare           0.000000\n",
       "Cabin          0.771044\n",
       "Embarked       0.002245\n",
       "dtype: float64"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()/len(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**the missing data(Age) = 20%**\n",
    "- so can't risk losing all of the data\n",
    "- Since it’s numerical, you could replace missing values with the median age to avoid skewing the distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Age'] = df['Age'].fillna(df['Age'].median())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**the missing data(Cabin) = 77%**\n",
    "- so can't fill the lose all of the data by predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['PassengerId', 'Survived', 'Pclass', 'Name', 'Sex', 'Age', 'SibSp',\n",
      "       'Parch', 'Ticket', 'Fare', 'Embarked'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "df.drop(columns=['Cabin'], inplace=True)\n",
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Embarked:**\n",
    "\n",
    "- Since it’s categorical and only has 2  missing values, you can fill in the mode (most common embarkation point)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\heba.raslan\\AppData\\Local\\Temp\\ipykernel_21128\\2531022806.py:1: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['Embarked'] = df['Embarked'].fillna(df['Embarked'].mode()[0], inplace=True)\n"
     ]
    }
   ],
   "source": [
    "df['Embarked'] = df['Embarked'].fillna(df['Embarked'].mode()[0], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassengerId      0\n",
       "Survived         0\n",
       "Pclass           0\n",
       "Name             0\n",
       "Sex              0\n",
       "Age              0\n",
       "SibSp            0\n",
       "Parch            0\n",
       "Ticket           0\n",
       "Fare             0\n",
       "Embarked       891\n",
       "dtype: int64"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.\tHandling Duplicates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`df.duplicated().sum()` returning `0`:**\n",
    "- This command checks for duplicate rows across all columns in the DataFrame.\n",
    "- If it returns `0`, it means that there are no complete duplicate rows in the DataFrame, where all columns have the same values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop duplicates if found\n",
    "# df.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`df.duplicated(subset=['Parch']).sum()` returning `884`:**\n",
    "- This command checks for duplicates only based on the `Parch` column.\n",
    "- The result of `884` indicates that there are `884` instances where the value of `Parch` is repeated in different rows.\n",
    "- It's important to note that these are not complete duplicates (where every column matches), but rather that many rows share the same value for `Parch`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "884"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.duplicated(subset=['Parch']).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(891, 11)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parch\n",
      "0    678\n",
      "1    118\n",
      "2     80\n",
      "5      5\n",
      "3      5\n",
      "4      4\n",
      "6      1\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df['Parch'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bins or Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.\tHandling Incorrect Data Types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassengerId      int64\n",
       "Survived         int64\n",
       "Pclass           int64\n",
       "Name            object\n",
       "Sex             object\n",
       "Age            float64\n",
       "SibSp            int64\n",
       "Parch            int64\n",
       "Ticket          object\n",
       "Fare           float64\n",
       "Embarked        object\n",
       "dtype: object"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`object`:** Typically used for string values or mixed types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 11 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   PassengerId  891 non-null    int64  \n",
      " 1   Survived     891 non-null    int64  \n",
      " 2   Pclass       891 non-null    int64  \n",
      " 3   Name         891 non-null    object \n",
      " 4   Sex          891 non-null    object \n",
      " 5   Age          891 non-null    float64\n",
      " 6   SibSp        891 non-null    int64  \n",
      " 7   Parch        891 non-null    int64  \n",
      " 8   Ticket       891 non-null    object \n",
      " 9   Fare         891 non-null    float64\n",
      " 10  Embarked     0 non-null      object \n",
      "dtypes: float64(2), int64(5), object(4)\n",
      "memory usage: 76.7+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Embarked  \n",
       "0      0         A/5 21171   7.2500     None  \n",
       "1      0          PC 17599  71.2833     None  \n",
       "2      0  STON/O2. 3101282   7.9250     None  \n",
       "3      0            113803  53.1000     None  \n",
       "4      0            373450   8.0500     None  "
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **String Conversion:** Converting `PassengerId` and `Ticket` to string makes it clear these columns aren’t for mathematical operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['PassengerId'] = df['PassengerId'].astype(str)\n",
    "df['Ticket'] = df['Ticket'].astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Category Conversion:** Converting `Pclass`, `Sex`, and `Embarked` to category reduces memory usage and prepares them for encoding steps later, making operations like grouping and aggregating more efficient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Pclass'] = df['Pclass'].astype('category')\n",
    "df['Sex'] = df['Sex'].astype('category')\n",
    "df['Embarked'] = df['Embarked'].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PassengerId      object\n",
      "Survived          int64\n",
      "Pclass         category\n",
      "Name             object\n",
      "Sex            category\n",
      "Age             float64\n",
      "SibSp             int64\n",
      "Parch             int64\n",
      "Ticket           object\n",
      "Fare            float64\n",
      "Embarked       category\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns in the DataFrame before encoding: Index(['PassengerId', 'Survived', 'Pclass', 'Name', 'Sex', 'Age', 'SibSp',\n",
      "       'Parch', 'Ticket', 'Fare', 'Embarked'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(\"Columns in the DataFrame before encoding:\", df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns in the DataFrame after encoding: Index(['PassengerId', 'Survived', 'Pclass', 'Name', 'Age', 'SibSp', 'Parch',\n",
      "       'Ticket', 'Fare', 'Embarked', 'Sex_male'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# One-hot encoding for categorical columns like Sex and Embarked\n",
    "df = pd.get_dummies(df, columns=['Sex'], drop_first=True)\n",
    "print(\"Columns in the DataFrame after encoding:\", df.columns)\n",
    "df = pd.get_dummies(df, columns=['Embarked'], drop_first=True)\n",
    "\n",
    "# Label encoding for Pclass (only if ordinal relationship is assumed)\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "df['Pclass'] = label_encoder.fit_transform(df['Pclass'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns in the DataFrame after encoding: Index(['PassengerId', 'Survived', 'Pclass', 'Name', 'Age', 'SibSp', 'Parch',\n",
      "       'Ticket', 'Fare', 'Sex_male'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(\"Columns in the DataFrame after encoding:\", df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For a column Pclass with values `[1, 2, 3]`, **Label Encoding** would produce:\n",
    "\n",
    "**Pclass**\n",
    "\n",
    "`   0        # Category 1`\n",
    "\n",
    "`   1        # Category 2`\n",
    "   \n",
    "`   2        # Category 3`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Summary**\n",
    "\n",
    "While category is primarily for efficient data handling and memory saving during the preprocessing phase, encoding these categorical columns to numerical formats is the final step before model training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.\tOutliers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Identifying Outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1.1 Statistical Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Z Score**\n",
    "\n",
    "- A Z-score measures how many standard deviations a data point is from the mean. \n",
    "- Z-score is finding the distribution of data where mean is 0 and standard deviation is 1 i.e. normal distribution.\n",
    "- While calculating the Z-score we re-scale and center the data and look for data points which are too far from zero. These data points which are way too far from zero will be treated as the outliers.\n",
    "- A common threshold for identifying outliers is a Z-score greater than 3 or less than -3.\n",
    "\n",
    "<img src='zscore.jpeg'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The absolute Z-score `(np.abs(...))` is taken to ensure that both extreme low and high values are considered."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def detect_outliers(column_name):\n",
    "    mean_col = np.mean(df[column_name])\n",
    "    std_dev_col = np.std(df[column_name])\n",
    "    z_scores_col = (df[column_name] - mean_col) / std_dev_col\n",
    "    outliers_col = df[column_name][np.abs(z_scores_col) > 3]  # Identify outliers\n",
    "    \n",
    "    # Calculate the number of outliers and the total rows in the dataset\n",
    "    num_outliers = outliers_col.shape[0]\n",
    "    total_rows = df.shape[0]\n",
    "    \n",
    "    print(f\"Outliers in '{column_name}' using Z-score:\\n\", outliers_col)\n",
    "    print(f\"\\nNumber of outliers in '{column_name}': {num_outliers} out of {total_rows} rows\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select numeric columns to calculate Z-scores (`Age`, `Fare`, `SibSp`, `Parch`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outliers in 'Age' using Z-score:\n",
      " 96     71.0\n",
      "116    70.5\n",
      "493    71.0\n",
      "630    80.0\n",
      "672    70.0\n",
      "745    70.0\n",
      "851    74.0\n",
      "Name: Age, dtype: float64\n",
      "\n",
      "Number of outliers in 'Age': 7 out of 891 rows\n"
     ]
    }
   ],
   "source": [
    "detect_outliers('Age')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The rows shown, such as `96`, `116`, and so on, represent the indices in the DataFrame where `Age` values were detected as outliers.\n",
    "- The values following each index, like `71.0` and `80.0`, are the actual ages that were identified as outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# detect_outliers('Fare')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# detect_outliers('SibSp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# detect_outliers('Parch')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**IQR (Interquartile Range)**\n",
    "- It is the difference between the third quartile and the first quartile (IQR = Q3 -Q1).\n",
    "- Outliers in this case are defined as the observations that are below (Q1 − 1.5x IQR) or boxplot lower whisker or above (Q3 + 1.5x IQR) or boxplot upper whisker.\n",
    "\n",
    "<img src='boxplot.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. **Calculate the IQR:** The IQR is defined as the difference between the 75th percentile (Q3) and the 25th percentile (Q1) of the data.\n",
    "2. **Define the outlier bounds:** Any data point below \n",
    "𝑄1−1.5×IQR or above 𝑄3+1.5×IQR is considered an outlier.\n",
    "3. Count the number of outliers and compare them to the total number of rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_outliers_iqr(column_name):\n",
    "    Q1 = np.percentile(df[column_name].dropna(), 25)\n",
    "    Q3 = np.percentile(df[column_name].dropna(), 75)\n",
    "    IQR = Q3 - Q1  # Calculate IQR\n",
    "    \n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "    \n",
    "    # Identify outliers\n",
    "    outliers_col = df[column_name][(df[column_name] < lower_bound) | (df[column_name] > upper_bound)]\n",
    "    \n",
    "    # Calculate the number of outliers and the total rows in the dataset\n",
    "    num_outliers = outliers_col.shape[0]\n",
    "    total_rows = df.shape[0]\n",
    "    \n",
    "    print(f\"Outliers in '{column_name}' using IQR:\\n\", outliers_col)\n",
    "    print(f\"\\nNumber of outliers in '{column_name}': {num_outliers} out of {total_rows} rows\")\n",
    "    \n",
    "    return lower_bound, upper_bound"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outliers in 'Age' using IQR:\n",
      " 7       2.00\n",
      "11     58.00\n",
      "15     55.00\n",
      "16      2.00\n",
      "33     66.00\n",
      "       ...  \n",
      "827     1.00\n",
      "829    62.00\n",
      "831     0.83\n",
      "851    74.00\n",
      "879    56.00\n",
      "Name: Age, Length: 66, dtype: float64\n",
      "\n",
      "Number of outliers in 'Age': 66 out of 891 rows\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(2.5, 54.5)"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "detect_outliers_iqr('Age')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# detect_outliers_iqr('Fare')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "# detect_outliers_iqr('SibSp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "# detect_outliers_iqr('Parch')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Skewness**\n",
    "- the skewness value should be within the range of -1 to 1 for a normal distribution, any major changes from this value may indicate the presence of outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "skewness value of Age:  0.5102446555756495\n",
      "skewness value of Fare:  4.787316519674893\n",
      "skewness value of Age:  3.6953517271630565\n",
      "skewness value of Fare:  2.7491170471010933\n"
     ]
    }
   ],
   "source": [
    "print('skewness value of Age: ',df['Age'].skew())\n",
    "print('skewness value of Fare: ',df['Fare'].skew())\n",
    "print('skewness value of Age: ',df['SibSp'].skew())\n",
    "print('skewness value of Fare: ',df['Parch'].skew())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Interpretation:** A skewness value of about `4.79` suggests a significant positive skew. This means that most passengers paid lower fares, with a few passengers having very high fares creating a long right tail. The distribution is highly asymmetric, indicating that a small number of high fare values heavily influence the average fare."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1.2 Visualization Methods (Box Plot)\n",
    "<img src='boxplot.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Box plots are typically used for **numeric columns** to show the distribution of data, identify outliers, and understand the central tendency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sns.boxplot(df['Age'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: ylabel='Fare'>"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.boxplot(df['Fare'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sns.boxplot(df['SibSp'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sns.boxplot(df['Parch'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Handle it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2.1 Flooring and Capping\n",
    "\n",
    "Replace outliers with the maximum or minimum values within the range."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Example:**\n",
    "\n",
    "Suppose we have an \"Age\" column with outliers below 10 and above 80. After detecting that 10 and 80 are our lower and upper bounds:\n",
    "\n",
    "- Flooring will replace all values below 10 with 10.\n",
    "- Capping will replace all values above 80 with 80."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "def floor_and_cap(column_name):\n",
    "    lower_bound, upper_bound = detect_outliers_iqr(column_name)  # Get bounds from IQR function\n",
    "    df[column_name] = np.where(df[column_name] < lower_bound, lower_bound, df[column_name])\n",
    "    df[column_name] = np.where(df[column_name] > upper_bound, upper_bound, df[column_name])\n",
    "    print(f\"Applied flooring and capping to '{column_name}' based on IQR limits.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "# floor_and_cap('Age')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "# floor_and_cap('Fare')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the boxplot below shows no presence of outliers\n",
    "# sns.boxplot(df['Fare'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2.2 Trimming (also called truncation)\n",
    "\n",
    " Remove extreme values entirely from the dataset.\n",
    "\n",
    " **When to Use Trimming?**\n",
    " \n",
    "Trimming is useful when:\n",
    "\n",
    "- You have a large dataset where removing a small percentage of data won’t affect the overall analysis.\n",
    "- You want to simplify the data distribution for models that are sensitive to outliers, such as linear regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trim_outliers(column_name):\n",
    "    lower_bound, upper_bound = detect_outliers_iqr(column_name)  # Get bounds from IQR function\n",
    "    # Print initial dimensions\n",
    "    initial_shape = df.shape\n",
    "    print(f\"\\nOriginal dataset shape: {initial_shape[0]} rows, {initial_shape[1]} columns\")\n",
    "    \n",
    "    # Keep only rows within the bounds\n",
    "    trimmed_df = df[(df[column_name] >= lower_bound) & (df[column_name] <= upper_bound)]\n",
    "    \n",
    "    # Print dimensions after trimming\n",
    "    trimmed_shape = trimmed_df.shape\n",
    "    print(f\"Dataset shape after trimming outliers in '{column_name}': {trimmed_shape[0]} rows, {trimmed_shape[1]} columns\")\n",
    "    \n",
    "    return trimmed_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trimmed_df_age = trim_outliers('Age')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2.3 Replacing outliers with the mean, median, mode, or other values\n",
    "1. **Replacing with the Mean:** \n",
    "\n",
    "    - if the data is approximately normally distributed, without strong skewness.\n",
    "2. **Replacing with the Median:** \n",
    "\n",
    "    - if the data has a strong skew, as it won’t be influenced by extreme values.\n",
    "    - This method is often preferred for data like income or home prices, where a few extreme values can distort the average.\n",
    "3. **Replacing with the Mode:**\n",
    "\n",
    "    - This is best for categorical or discrete data where a common or most frequent value makes sense.\n",
    "    - Use this for data like `SibSp` (number of siblings/spouses) or other count-based features, where the most frequent count can replace outliers effectively.\n",
    "4. **Replacing with Other Values:**\n",
    "    - You can also use custom values depending on the context. For instance, you might set outliers in an age column to a certain threshold, such as 100, for practical reasons."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. **Replacing Outliers in 'Age' with the Median**\n",
    "\n",
    "    - Since Age often has missing values and can be skewed (for instance, children and the elderly), using the median provides a robust, outlier-resistant estimate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outliers in 'Age' using IQR:\n",
      " 7       2.00\n",
      "11     58.00\n",
      "15     55.00\n",
      "16      2.00\n",
      "33     66.00\n",
      "       ...  \n",
      "827     1.00\n",
      "829    62.00\n",
      "831     0.83\n",
      "851    74.00\n",
      "879    56.00\n",
      "Name: Age, Length: 66, dtype: float64\n",
      "\n",
      "Number of outliers in 'Age': 66 out of 891 rows\n"
     ]
    }
   ],
   "source": [
    "# Calculate the median of 'Age'\n",
    "median_age = df['Age'].median()\n",
    "age_lower, age_upper = detect_outliers_iqr('Age') \n",
    "# Replace outliers in 'Age' with the median\n",
    "df['Age'] = np.where((df['Age'] < age_lower) | (df['Age'] > age_upper), median_age, df['Age']) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. **Replacing Outliers in 'Fare' with the Mean**\n",
    "    - Fare has a long tail due to high-ticket prices for first-class passengers.\n",
    "    - However, replacing outliers with the mean makes sense here because we’re not as concerned about the skewness for ticket prices, and the mean value represents an average fare that is useful in calculating overall trends."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outliers in 'Fare' using IQR:\n",
      " 1       71.2833\n",
      "27     263.0000\n",
      "31     146.5208\n",
      "34      82.1708\n",
      "52      76.7292\n",
      "         ...   \n",
      "846     69.5500\n",
      "849     89.1042\n",
      "856    164.8667\n",
      "863     69.5500\n",
      "879     83.1583\n",
      "Name: Fare, Length: 116, dtype: float64\n",
      "\n",
      "Number of outliers in 'Fare': 116 out of 891 rows\n"
     ]
    }
   ],
   "source": [
    "# Calculate the mean of 'Fare'\n",
    "mean_fare = df['Fare'].mean()\n",
    "fare_lower, fare_upper = detect_outliers_iqr('Fare') \n",
    "# Replace outliers in 'Fare' with the mean\n",
    "df['Fare'] = np.where((df['Fare'] < fare_lower) | (df['Fare'] > fare_upper), mean_fare, df['Fare'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. **Replacing Outliers in 'SibSp' and 'Parch' with the Mode**\n",
    "    - SibSp (number of siblings/spouses) and Parch (number of parents/children) are count-based discrete variables, so using the mode (most common value) is appropriate for replacing outliers.\n",
    "    - These columns have a natural lower bound (0 family members), so setting outliers to the mode ensures we’re using a logical replacement without adding non-integer or average values to a count field."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the mode of 'SibSp' and 'Parch'\n",
    "mode_sibsp = df['SibSp'].mode()[0]\n",
    "mode_parch = df['Parch'].mode()[0]\n",
    "\n",
    "# Replace outliers in 'SibSp' with the mode\n",
    "df['SibSp'] = np.where((df['SibSp'] < 0) | (df['SibSp'] > 8), mode_sibsp, df['SibSp'])\n",
    "# Replace outliers in 'Parch' with the mode\n",
    "df['Parch'] = np.where((df['Parch'] < 0) | (df['Parch'] > 6), mode_parch, df['Parch'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5.\tHandling Inconsistent Data # # #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique values in 'Pclass': [2 0 1]\n",
      "Unique values in 'Sex_male': [ True False]\n"
     ]
    }
   ],
   "source": [
    "# Check for inconsistencies in 'Pclass', 'Sex', and 'Embarked'\n",
    "print(\"Unique values in 'Pclass':\", df['Pclass'].unique())\n",
    "print(\"Unique values in 'Sex_male':\", df['Sex_male'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6.\tFeature Scaling and Normalization (New Task)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Bring all features into a similar range"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. **Standardization (Z-score normalization)**\n",
    "\n",
    "    - **Purpose:** Centers data around zero with a unit standard deviation, making it suitable for algorithms that assume normally distributed data.\n",
    "    - **Formula:** `𝑧=(𝑥−mean)/standard deviation`\n",
    "    - **When to Use:** Suitable for algorithms like linear regression, logistic regression, and K-means clustering, where distances or assumptions of normally distributed data matter.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "df[['Age', 'Fare']] = scaler.fit_transform(df[['Age', 'Fare']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. **Min-Max Scaling (Normalization)**\n",
    "\n",
    "    - **Purpose:** Scales features to a fixed range, typically `[0,1]` or `[-1,1]`, preserving relative relationships.\n",
    "    - **Formula:** `Xscaled=(X−Xmin)/(Xmax−Xmin)`\n",
    "    - **When to Use:** Recommended for algorithms like neural networks and K-nearest neighbors (KNN), as they perform better with data within a defined range."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "df[['Age', 'Fare']] = scaler.fit_transform(df[['Age', 'Fare']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. **Robust Scaling**\n",
    "\n",
    "    - **Purpose:** Scales features based on median and interquartile range, reducing the impact of outliers.\n",
    "    - **Formula:** `Xscaled = (X−median)/IQR`\n",
    "    - **When to Use:** Ideal when your data has many outliers, as it mitigates their influence.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import RobustScaler\n",
    "scaler = RobustScaler()\n",
    "df[['Age', 'Fare']] = scaler.fit_transform(df[['Age', 'Fare']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. **Max Abs Scaling**\n",
    "\n",
    "    - **Purpose:** Scales data by dividing each feature by its maximum absolute value, preserving the sign of each value.\n",
    "    - **Formula:** `Xscaled = X / ∣Xmax∣`\n",
    "    - **When to Use:** Commonly used when the data is already centered at zero and sparse, as it preserves zero entries in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MaxAbsScaler\n",
    "scaler = MaxAbsScaler()\n",
    "df[['Age', 'Fare']] = scaler.fit_transform(df[['Age', 'Fare']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. **L1 and L2 Normalization**\n",
    "\n",
    "    - **Purpose:** Scales data based on the sum of absolute values (L1) or sum of squares (L2) for unit length, making vector lengths equal.\n",
    "    - **Formulas:**\n",
    "        - L1: `𝑋scaled = 𝑋 / ∑∣𝑋∣`\n",
    "        - L2: `Xscaled = 𝑋 / √∑X²`\n",
    "    - **Use Case:** Used in machine learning algorithms that rely on distance metrics, such as K-means clustering or nearest neighbors. L2 is more common than L1.\n",
    "​\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. **Decimal Scaling**\n",
    "\n",
    "    - **Purpose:** Moves decimal places to bring values within a certain range.\n",
    "    - **Formula:** `Xscaled = X / 10^𝑗` where 𝑗 is the smallest integer such that all values fall between -1 and 1.\n",
    "    - **Use Case:** When you need to scale data quickly and approximately, especially when precise min-max ranges aren’t known. Rarely used in practice."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. **Log Transformation**\n",
    "\n",
    "    - **Purpose:** Reduces skewness and stabilizes variance, bringing data closer to a normal distribution.\n",
    "    - **Formula:** `𝑋transformed = log(𝑋+𝑐)X`  where 𝑐 is a constant to avoid log(0) issues.\n",
    "    - **Use Case:** Effective for right-skewed data with a wide range of positive values. Often used before machine learning models to make the data more symmetric."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. **Power Transformation**\n",
    "\n",
    "    - **Purpose:** Reduces skewness and makes the data more normally distributed.\n",
    "    - **Formulas:**\n",
    "        - Box-Cox: For positive data only, \n",
    "        \n",
    "            `𝑋transformed = (𝑋^𝜆 − 1) / 𝜆`  for `𝜆≠0`.\n",
    "        - Yeo-Johnson: Extends to both positive and negative values.\n",
    "    - **Use Case:** When data has significant skewness and variance instability. Helps certain algorithms by ensuring the data follows a Gaussian distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Normalization Technique       | When to Use                                                                                               |\n",
    "|-------------------------------|-----------------------------------------------------------------------------------------------------------|\n",
    "| Min-Max Scaling               | When you want to normalize data to a fixed range, typically [0, 1]. Useful for data with varying ranges. |\n",
    "| Z-score Normalization         | When your data follows a Gaussian distribution. Helps to bring the mean to 0 and standard deviation to 1.|\n",
    "| Robust Scaling                | Effective for datasets with outliers. Scales data according to the median and the interquartile range.   |\n",
    "| Max Abs Scaling               | Useful for data already centered at zero and needs to be scaled to the range [-1, 1].                     |\n",
    "| L1 and L2 Normalization       | Converts features into a unit vector. Commonly used in text classification and clustering.               |\n",
    "| Decimal Scaling               | Normalizes data based on the number of digits.                                                           |\n",
    "| Log Transformation            | Effective for positively skewed distributions, helping to reduce skewness.                                |\n",
    "| Power Transformation          | Useful for transforming non-Gaussian data into a Gaussian-like distribution.                              |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7.\tHandling Categorical Variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Label encoding is used to convert categorical values into numeric ones.\n",
    "- already done after \"3.\tHandling Incorrect Data Types\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8.\tHandling String Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.1 String Cleaning\n",
    "\n",
    "- replace any character that is not a word character `(\\w)` or whitespace `(\\s)` with an empty string. This cleaning helps normalize the names and prepares them for further analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                Braund, Mr. Owen Harris\n",
       "1      Cumings, Mrs. John Bradley (Florence Briggs Th...\n",
       "2                                 Heikkinen, Miss. Laina\n",
       "3           Futrelle, Mrs. Jacques Heath (Lily May Peel)\n",
       "4                               Allen, Mr. William Henry\n",
       "                             ...                        \n",
       "886                                Montvila, Rev. Juozas\n",
       "887                         Graham, Miss. Margaret Edith\n",
       "888             Johnston, Miss. Catherine Helen \"Carrie\"\n",
       "889                                Behr, Mr. Karl Howell\n",
       "890                                  Dooley, Mr. Patrick\n",
       "Name: Name, Length: 891, dtype: object"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Removes punctuation\n",
    "df['Name'] = df['Name'].str.replace(r'[^\\w\\s]', '')  \n",
    "df['Name']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.2 Lowercasing\n",
    "\n",
    "- eliminate case sensitivity, making it easier to match and analyze names without treating \"Smith\" and \"smith\" as different entries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                braund, mr. owen harris\n",
       "1      cumings, mrs. john bradley (florence briggs th...\n",
       "2                                 heikkinen, miss. laina\n",
       "3           futrelle, mrs. jacques heath (lily may peel)\n",
       "4                               allen, mr. william henry\n",
       "                             ...                        \n",
       "886                                montvila, rev. juozas\n",
       "887                         graham, miss. margaret edith\n",
       "888             johnston, miss. catherine helen \"carrie\"\n",
       "889                                behr, mr. karl howell\n",
       "890                                  dooley, mr. patrick\n",
       "Name: Name, Length: 891, dtype: object"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Name'] = df['Name'].str.lower()\n",
    "df['Name']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.3 Tokenization\n",
    "\n",
    "- The 'Name' column can be split into first and last names or other relevant tokens.\n",
    "- creates a new column where each name is represented as a list of tokens (words).\n",
    "- This can be useful for analyzing titles or separating names for feature extraction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                           [braund,, mr., owen, harris]\n",
       "1      [cumings,, mrs., john, bradley, (florence, bri...\n",
       "2                             [heikkinen,, miss., laina]\n",
       "3      [futrelle,, mrs., jacques, heath, (lily, may, ...\n",
       "4                          [allen,, mr., william, henry]\n",
       "                             ...                        \n",
       "886                            [montvila,, rev., juozas]\n",
       "887                    [graham,, miss., margaret, edith]\n",
       "888       [johnston,, miss., catherine, helen, \"carrie\"]\n",
       "889                           [behr,, mr., karl, howell]\n",
       "890                              [dooley,, mr., patrick]\n",
       "Name: Name_Tokens, Length: 891, dtype: object"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Name_Tokens'] = df['Name'].str.split()\n",
    "df['Name_Tokens']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.4 Removing Titles from Names\n",
    "\n",
    "- Extract useful information from names that can be treated as features.\n",
    "-  Titles like \"Mr.\", \"Mrs.\", \"Miss\" provide insight into gender and social status.\n",
    "- `(\\w+)`: This part captures the title."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        mr\n",
       "1       mrs\n",
       "2      miss\n",
       "3       mrs\n",
       "4        mr\n",
       "       ... \n",
       "886     rev\n",
       "887    miss\n",
       "888    miss\n",
       "889      mr\n",
       "890      mr\n",
       "Name: Title, Length: 891, dtype: object"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Title'] = df['Name'].str.extract(r', (\\w+)\\.')\n",
    "df['Title']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.5 Concatenating Columns\n",
    "\n",
    "- Combine multiple columns into a single feature for better representation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Title_Name'] = df['Title'] + ' ' + df['Name']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 9.\tData Binning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Binning divides continuous numerical data into discrete intervals, making it easier to analyze."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Types of Binning**\n",
    "\n",
    "1. **Equal-Width Binning:** Divides the range of data into equal-sized intervals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Age_bin_equal_width</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.230769</td>\n",
       "      <td>Young Adult</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.384615</td>\n",
       "      <td>Adult</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.076923</td>\n",
       "      <td>Young Adult</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.269231</td>\n",
       "      <td>Adult</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.269231</td>\n",
       "      <td>Adult</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>-0.038462</td>\n",
       "      <td>Young Adult</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>-0.346154</td>\n",
       "      <td>Young Adult</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>Young Adult</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>-0.076923</td>\n",
       "      <td>Young Adult</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>0.153846</td>\n",
       "      <td>Adult</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>891 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Age Age_bin_equal_width\n",
       "0   -0.230769         Young Adult\n",
       "1    0.384615               Adult\n",
       "2   -0.076923         Young Adult\n",
       "3    0.269231               Adult\n",
       "4    0.269231               Adult\n",
       "..        ...                 ...\n",
       "886 -0.038462         Young Adult\n",
       "887 -0.346154         Young Adult\n",
       "888  0.000000         Young Adult\n",
       "889 -0.076923         Young Adult\n",
       "890  0.153846               Adult\n",
       "\n",
       "[891 rows x 2 columns]"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Age_bin_equal_width'] = pd.cut(df['Age'], bins=4, labels=['Child', 'Young Adult', 'Adult', 'Senior'])\n",
    "df[['Age', 'Age_bin_equal_width']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Age_bin_equal_frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.230769</td>\n",
       "      <td>Q1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.384615</td>\n",
       "      <td>Q4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.076923</td>\n",
       "      <td>Q2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.269231</td>\n",
       "      <td>Q4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.269231</td>\n",
       "      <td>Q4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>-0.038462</td>\n",
       "      <td>Q2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>-0.346154</td>\n",
       "      <td>Q1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>Q2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>-0.076923</td>\n",
       "      <td>Q2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>0.153846</td>\n",
       "      <td>Q3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>891 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Age Age_bin_equal_frequency\n",
       "0   -0.230769                      Q1\n",
       "1    0.384615                      Q4\n",
       "2   -0.076923                      Q2\n",
       "3    0.269231                      Q4\n",
       "4    0.269231                      Q4\n",
       "..        ...                     ...\n",
       "886 -0.038462                      Q2\n",
       "887 -0.346154                      Q1\n",
       "888  0.000000                      Q2\n",
       "889 -0.076923                      Q2\n",
       "890  0.153846                      Q3\n",
       "\n",
       "[891 rows x 2 columns]"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Age_bin_equal_frequency'] = pd.qcut(df['Age'], q=4, labels=['Q1', 'Q2', 'Q3', 'Q4'])\n",
    "df[['Age', 'Age_bin_equal_frequency']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. **Custom Binning:** Creates bins based on domain knowledge or specific intervals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Age_bin_custom</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.230769</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.384615</td>\n",
       "      <td>Child</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.076923</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.269231</td>\n",
       "      <td>Child</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.269231</td>\n",
       "      <td>Child</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>-0.038462</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>-0.346154</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>-0.076923</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>0.153846</td>\n",
       "      <td>Child</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>891 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Age Age_bin_custom\n",
       "0   -0.230769            NaN\n",
       "1    0.384615          Child\n",
       "2   -0.076923            NaN\n",
       "3    0.269231          Child\n",
       "4    0.269231          Child\n",
       "..        ...            ...\n",
       "886 -0.038462            NaN\n",
       "887 -0.346154            NaN\n",
       "888  0.000000            NaN\n",
       "889 -0.076923            NaN\n",
       "890  0.153846          Child\n",
       "\n",
       "[891 rows x 2 columns]"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bins = [0, 12, 18, 35, 60, np.inf]\n",
    "labels = ['Child', 'Teen', 'Young Adult', 'Adult', 'Senior']\n",
    "df['Age_bin_custom'] = pd.cut(df['Age'], bins=bins, labels=labels)\n",
    "df[['Age', 'Age_bin_custom']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Choosing the Right Binning Technique**\n",
    "- Equal-Width: Suitable when data has a uniform distribution.\n",
    "- Equal-Frequency: Ideal for skewed data or when you want each bin to have a similar number of observations.\n",
    "- Custom Binning: Useful if you have domain knowledge about meaningful groupings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 10.\tFeature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Handling Categorical Variables\n",
    "- One-Hot Encoding: Used to convert categorical columns into binary columns (e.g., Sex, Embarked).\n",
    "- Label Encoding: Assigns a unique numerical value to each category (helpful for ordinal data).\n",
    "### 2. Creating New Features\n",
    "- Title Extraction: Titles like \"Mr.\", \"Mrs.\", etc., can be extracted from the Name column, providing information about social status, which may impact survival chances.\n",
    "### 3. Binning\n",
    "- Converting continuous variables into categorical groups can improve model interpretability, especially if relationships are nonlinear.\n",
    "### 4. Transforming Features\n",
    "- Log Transformation: Used to reduce skewness in features like Fare, where some outliers can distort the model.\n",
    "- Scaling: Normalize or standardize features to ensure equal influence in distance-based models (like k-NN or SVM)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     -0.142528\n",
       "1      0.351167\n",
       "2     -0.129174\n",
       "3      0.764570\n",
       "4     -0.126701\n",
       "         ...   \n",
       "886   -0.028770\n",
       "887    0.307559\n",
       "888    0.177973\n",
       "889    0.307559\n",
       "890   -0.132636\n",
       "Name: Fare, Length: 891, dtype: float64"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Fare']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     -0.153767\n",
       "1      0.300969\n",
       "2     -0.138313\n",
       "3      0.567907\n",
       "4     -0.135477\n",
       "         ...   \n",
       "886   -0.029192\n",
       "887    0.268162\n",
       "888    0.163795\n",
       "889    0.268162\n",
       "890   -0.142297\n",
       "Name: Fare_log, Length: 891, dtype: float64"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example (Log Transformation)\n",
    "df['Fare_log'] = np.log1p(df['Fare'])\n",
    "df['Fare_log']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 11.\tHandling Data Encoding Issues # #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 12.\tData Aggregation and Grouping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "are essential techniques for summarizing and analyzing data, often used to extract meaningful insights and answer questions about the data. In the Titanic dataset, for example, we might want to know the average fare paid by each class, or the survival rate by gender."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. **Grouping:** Organizes the data based on unique values in a column or set of columns, creating “groups” for each unique value or combination of values.\n",
    "\n",
    "    - For instance, grouping the Titanic dataset by \"Pclass\" creates separate groups for each passenger class (1, 2, or 3).\n",
    "2. **Aggregation:** Applies functions that summarize data within each group, such as calculating the mean, sum, count, or median.\n",
    "\n",
    "    - After grouping by \"Pclass,\" we can aggregate to find the average fare or survival rate within each passenger class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example Use Cases in the Titanic Dataset\n",
    "1. **Grouping by Single Column**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pclass\n",
       "0    0.629630\n",
       "1    0.472826\n",
       "2    0.242363\n",
       "Name: Survived, dtype: float64"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "survival_by_class = df.groupby('Pclass')['Survived'].mean()\n",
    "survival_by_class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. **Grouping by Multiple Columns**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pclass  Sex_male\n",
       "0       False       0.968085\n",
       "        True        0.368852\n",
       "1       False       0.921053\n",
       "        True        0.157407\n",
       "2       False       0.500000\n",
       "        True        0.135447\n",
       "Name: Survived, dtype: float64"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "survival_by_class_and_gender = df.groupby(['Pclass', 'Sex_male'])['Survived'].mean()\n",
    "survival_by_class_and_gender"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. **Aggregating Multiple Statistics**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Fare</th>\n",
       "      <th>Survived</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>mean</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pclass</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.400907</td>\n",
       "      <td>0.629630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.100618</td>\n",
       "      <td>0.472826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.025938</td>\n",
       "      <td>0.242363</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Fare  Survived\n",
       "            mean      mean\n",
       "Pclass                    \n",
       "0       0.400907  0.629630\n",
       "1       0.100618  0.472826\n",
       "2      -0.025938  0.242363"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_stats = df.groupby('Pclass').agg({'Fare': ['mean'], 'Survived': 'mean'})\n",
    "class_stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. **Aggregating on Different Columns**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     Fare Survived\n",
      "                     mean      sum\n",
      "Pclass Sex_male                   \n",
      "0      False     0.425230       91\n",
      "       True      0.382167       45\n",
      "1      False     0.148695       70\n",
      "       True      0.066786       17\n",
      "2      False     0.017540       72\n",
      "       True     -0.043981       47\n"
     ]
    }
   ],
   "source": [
    "class_gender_stats = df.groupby(['Pclass', 'Sex_male']).agg({'Fare': ['mean'], 'Survived': 'sum'})\n",
    "print(class_gender_stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 13.\tReshaping Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 14.\tHandling Multicollinearity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 15.\tHandling Date and Time Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 16.\tData Merging and Joining"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 17.\tDealing with Sparse Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 18.\tType Casting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "New task \n",
    "\n",
    "Data normalization techniques \n",
    "\n",
    "\t1.\tMin-Max Scaling\n",
    "\t2.\tZ-score Normalization (Standardization)\n",
    "\t3.\tRobust Scaling\n",
    "\t4.\tMax Abs Scaling\n",
    "\t5.\tL1 and L2 Normalization\n",
    "\t6.\tDecimal Scaling\n",
    "\t7.\tLog Transformation\n",
    "\t8.\tPower Transformation \n",
    "\t\n",
    "Please find the solution where we have to use each technique ?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "new_headway",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
